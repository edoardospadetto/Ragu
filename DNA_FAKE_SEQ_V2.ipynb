{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Really complicated dna differentiation\n",
    "\n",
    "Imagine a chain of nucleotides, divided in genes and intragenic DNA. Genes must be functioning, so they have a pattern, intragenic DNA not, so it can be random.\n",
    "\n",
    "...intagrenic----gene----intragenic---gene---intragenic....\n",
    "\n",
    "GENES\n",
    "\n",
    "We have N genes Genes have the same order among neanderthal and humans:\n",
    "\n",
    "Hair--Height--Eyes--Beard.. <- Neanderthal Hair--Height--Eyes--Beard.. <- Human\n",
    "\n",
    "Humans and neanderthal are similar, so they have similar genes. Hence for a sigle gene i decided to have different variants, like brown hair, blond hairs, but they have to differ for small variation otherwise you would be bald.\n",
    "\n",
    "From a logic point of view, change a small number of nucleotides from a random sequence so you have the variants, but they keep the same lenght in all the variants.\n",
    "\n",
    "Genes have correlations between themselves, decided randomly between a random number of genes. For example Genes 1,8,15 are correlated in humans, correlations between 3 elements-> why? 3 is sampled from a \"discrete gaussian\", why 1,8,15 choseen random.\n",
    "\n",
    "INTRAGENIC\n",
    "\n",
    "We have N+1 intragenic sequence, of variable lenght interposed between genes.\n",
    "\n",
    "How humans differ from neanderthal??\n",
    "\n",
    "Intragenic dna different in lenght, for example in a human intragenic dna between genes 1 and 2, contains 100 nucleotides, while in the neanderthal 90. Correlations between different genes. like neanderthal correlates Nose and Beard, while human Height and Fat percentage.\n",
    "\n",
    "How humans differ from humans and neanderthal from neanderthal?\n",
    "\n",
    "Same intragenic lenght, but different nucleotides. Different genes variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manopole\n",
    "#decide the percentage of geneDNA in a sentence.\n",
    "pc_genes=0.7\n",
    "\n",
    "#How many genes?\n",
    "N_genes= 100\n",
    "\n",
    "#Choose genes to correlate\n",
    "\n",
    "#How many?\n",
    "avg_dimension_of_correlation_clusters=10\n",
    "\n",
    "b=0.4 #how different are different genes ? max 0.5\n",
    "fraction_of_mutations_per_gene=0.1#percentage of random mutations in gene variants\n",
    "variants=4 #how may variants?\n",
    "\n",
    "\n",
    "N_people= 4000\n",
    "sentence_length= 3000 #HOW LONG A SENTENCE in letters\n",
    "\n",
    "\n",
    "word_length=5 #HOW LONG A WORD in letters\n",
    "\n",
    "#do you want same intragenic location in neanderthals and humans?\n",
    "same = True\n",
    "\n",
    "#Sorry i did not implemented different genes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100.0\n",
      "900.0\n",
      "900.0\n",
      "900.0\n",
      "[29. 21. 19. 27. 31. 22. 11. 20. 19. 15. 18. 19. 18. 20. 20. 18. 14. 23.\n",
      " 19. 21. 27. 25. 24. 13. 32. 25. 32. 28. 17. 20. 22. 23. 20. 22. 21. 23.\n",
      " 25. 24. 18. 11. 23. 25. 17. 29. 22. 24. 18. 16. 21. 22. 27. 20. 27. 16.\n",
      " 19. 23. 28. 16. 16. 14. 10. 21. 14. 12. 22. 20. 19. 16. 34. 18. 16. 19.\n",
      " 22. 15. 21. 18. 16. 28. 13. 28. 20. 19. 19. 17. 24. 27. 17. 23. 24. 21.\n",
      " 20. 28. 20. 34. 22. 26. 20. 19. 12. 27.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Build Genes\n",
    "\n",
    "genes_nucleotides = (sentence_length*pc_genes) //1 \n",
    "intragenic_nucleotides= sentence_length - genes_nucleotides\n",
    "\n",
    "print(genes_nucleotides)\n",
    "print(intragenic_nucleotides)\n",
    "\n",
    "#How many intergenic sequences?\n",
    "N_intragenic=N_genes+1\n",
    "\n",
    "\n",
    "\n",
    "def split_in_different_leghts_sequence(how_many_nucleotides_for_genes, how_many_sequences):\n",
    "    N_n=how_many_nucleotides_for_genes\n",
    "    N_s=how_many_sequences\n",
    "    seqs=np.zeros(N_s)\n",
    "    for i in range(len(seqs)-1):\n",
    "        while(True):\n",
    "            ls=int(np.random.poisson((N_n/N_s)))\n",
    "            if ls>1: \n",
    "                break\n",
    "        N_n=N_n-ls\n",
    "        N_s=N_s-1\n",
    "        seqs[i]=int(ls)\n",
    "    seqs[-1]=N_n\n",
    "    return(seqs)\n",
    "\n",
    "\n",
    "genes_char=split_in_different_leghts_sequence(genes_nucleotides, N_genes)\n",
    "intragenic_char_humans=split_in_different_leghts_sequence(intragenic_nucleotides, N_intragenic)\n",
    "if same == False : \n",
    "    intragenic_char_neanderthal=split_in_different_leghts_sequence(intragenic_nucleotides, N_intragenic)\n",
    "else :\n",
    "    intragenic_char_neanderthal=intragenic_char_humans\n",
    "\n",
    "\n",
    "print(sum(intragenic_char_neanderthal))\n",
    "print(sum(intragenic_char_humans))\n",
    "print(genes_char)\n",
    "\n",
    "#Now I have the characterization of all genic and intragenic sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theese are the correlation cluster, dont worry about the NAN it simply means that this cluster is smaller thna the number of columns\n",
      "human\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>45.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>42.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>72.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>77.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>63</td>\n",
       "      <td>85</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>87</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2     3     4     5     6     7     8     9    10    11    12  \\\n",
       "0   71  38  44  45.0  96.0  97.0  75.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1    8  69  19  80.0  65.0  43.0  79.0  66.0  59.0   NaN   NaN   NaN   NaN   \n",
       "2    9  25  61   4.0  54.0   7.0  41.0  76.0  74.0   NaN   NaN   NaN   NaN   \n",
       "3   10  20  55  42.0  93.0  52.0  48.0  73.0  84.0  15.0   NaN   NaN   NaN   \n",
       "4   35  56  13  22.0  29.0  32.0  88.0   5.0  81.0  98.0  51.0  95.0  36.0   \n",
       "5   70  78   6  72.0  18.0  94.0  17.0  58.0  47.0  64.0   NaN   NaN   NaN   \n",
       "6   53  12  37  26.0  31.0   0.0  23.0  92.0   NaN   NaN   NaN   NaN   NaN   \n",
       "7   24  28  16  77.0  91.0  82.0  90.0   1.0  14.0  49.0  83.0  99.0   NaN   \n",
       "8   33  63  85  40.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "9   87  46  68  67.0  21.0  39.0  11.0  60.0  86.0  62.0   NaN   NaN   NaN   \n",
       "10   2  50  34   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "11  57   3  27   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "      13    14  \n",
       "0    NaN   NaN  \n",
       "1    NaN   NaN  \n",
       "2    NaN   NaN  \n",
       "3    NaN   NaN  \n",
       "4   89.0  30.0  \n",
       "5    NaN   NaN  \n",
       "6    NaN   NaN  \n",
       "7    NaN   NaN  \n",
       "8    NaN   NaN  \n",
       "9    NaN   NaN  \n",
       "10   NaN   NaN  \n",
       "11   NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neandertal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>84</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>54</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>93</td>\n",
       "      <td>59.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>61</td>\n",
       "      <td>21.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5     6     7     8     9    10    11    12    13  \\\n",
       "0  58  69  77  28  41  78   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1  94  72  73  32  34  36  30.0  23.0  49.0   NaN   NaN   NaN   NaN   NaN   \n",
       "2  80  67  18  43  45  38  70.0   9.0   6.0  51.0  57.0  24.0   NaN   NaN   \n",
       "3  56  31  26  64  37   3  86.0  16.0  25.0  62.0  52.0   7.0  96.0  44.0   \n",
       "4   0  60  63  35  29  84  95.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "5  79  65  10  92  17  81   1.0  42.0  99.0   NaN   NaN   NaN   NaN   NaN   \n",
       "6   4  97  54  87  82  48  15.0  40.0  90.0  53.0  66.0  50.0  13.0  89.0   \n",
       "7  46   8  74  68  22  93  59.0  55.0  71.0  39.0   NaN   NaN   NaN   NaN   \n",
       "8  85  27  98  83  88  75  47.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "9  12   5   2  19  33  61  21.0  91.0  76.0  20.0   NaN   NaN   NaN   NaN   \n",
       "\n",
       "     14    15  \n",
       "0   NaN   NaN  \n",
       "1   NaN   NaN  \n",
       "2   NaN   NaN  \n",
       "3   NaN   NaN  \n",
       "4   NaN   NaN  \n",
       "5   NaN   NaN  \n",
       "6  11.0  14.0  \n",
       "7   NaN   NaN  \n",
       "8   NaN   NaN  \n",
       "9   NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def correlate_genes(N_genes,cluster_dim):\n",
    "    clusters=[]\n",
    "    genes=[i for i in range((N_genes))]\n",
    "    while(len(genes) != 0):\n",
    "        while (True):\n",
    "            curr_cl= int(np.random.poisson((cluster_dim)))\n",
    "            if curr_cl <= len(genes) and curr_cl>0: break\n",
    "            #else: print(curr_cl, len(genes))\n",
    "        clusters.append(np.random.choice(genes, curr_cl, False))\n",
    "        for c in clusters[-1]:\n",
    "            genes.remove(c)\n",
    "    return((clusters))\n",
    "\n",
    "corrs_human=correlate_genes(N_genes,avg_dimension_of_correlation_clusters)\n",
    "corrs_neanderthal=correlate_genes(N_genes,avg_dimension_of_correlation_clusters)\n",
    "print(\"Theese are the correlation cluster, dont worry about the NAN it simply means that this cluster is smaller thna the number of columns\")       \n",
    "print(\"human\")\n",
    "display(pd.DataFrame(corrs_human)) \n",
    "print(\"neandertal\")\n",
    "display(pd.DataFrame(corrs_neanderthal))\n",
    "\n",
    "#Now i got the genes that are correlated.\n",
    "#In future we can include different genes correlations between human and neanderthal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you got these number of variants per gene :  4\n"
     ]
    }
   ],
   "source": [
    "#Now let's build the genes and their variants.\n",
    "\n",
    "var=variants-1 # ;) read the code and you'll know why\n",
    "genes=[]\n",
    "\n",
    "#Here we build the single gene\n",
    "\n",
    "for i in range(N_genes):    \n",
    "    tmp_var=np.random.random(4)*2*b +(0.5-b)\n",
    "    distr_f_a_gene=tmp_var/sum(tmp_var)\n",
    "    #print(np.cumsum(distr_f_a_gene))\n",
    "    genes_tmp=[]\n",
    "    for j in range(int(genes_char[i])): \n",
    "        MC_1=np.random.random(1)\n",
    "        which_nucleotide=0\n",
    "        for lim in np.cumsum(distr_f_a_gene):\n",
    "            if(MC_1<=lim): \n",
    "                genes_tmp.append(which_nucleotide)\n",
    "                MC_1= 0\n",
    "                break\n",
    "            else:   which_nucleotide+=1 \n",
    "    genes.append(genes_tmp)\n",
    "#now add random mutations to characterize each variant.\n",
    "#we'll have genes->n variants\n",
    "genes_nv=genes\n",
    "genes=[]\n",
    "#print(genes[0][0])\n",
    "\n",
    "i=0\n",
    "for gene in genes_nv:\n",
    "    tmp_var=[]\n",
    "    tmp_var.append(gene)\n",
    "    for j in range(var) :\n",
    "        mutations_where=[]\n",
    "        mutations_where=np.random.choice(range(len(gene)), \n",
    "                                    (int(fraction_of_mutations_per_gene*len(gene))) , False)\n",
    "        #print(range(len(gene)))\n",
    "        \n",
    "        tmp_a=list(gene)\n",
    "        for m_w in mutations_where:\n",
    "            tmp_a[m_w]=np.random.randint(4)\n",
    "            \n",
    "        tmp_var.append(tmp_a)\n",
    "    genes.append(tmp_var)\n",
    "        \n",
    "print(\"you got these number of variants per gene : \",len(genes[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07596469 0.13976462 0.40151494 0.40536303]\n",
      " [0.2412112  0.33606007 0.48144429 0.43657786]\n",
      " [0.78634637 0.71374491 0.60228467 0.66641489]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.34199921 0.43192543 0.43918212 0.15563738]\n",
      " [0.65374494 0.73713248 0.72277922 0.59781427]\n",
      " [0.98933074 0.91487176 0.91907352 0.6049072 ]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.04327732 0.52364077 0.01266824 0.45529154]\n",
      " [0.59535855 0.53091516 0.09366998 0.65837482]\n",
      " [0.61164403 0.66257642 0.4682903  0.79909541]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.09511649 0.5019994  0.06149604 0.18618819]\n",
      " [0.3861344  0.58228108 0.36578834 0.3198758 ]\n",
      " [0.63112959 0.99863137 0.74439389 0.59033468]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.02989139 0.58369466 0.14812177 0.04439152]\n",
      " [0.45225362 0.68981853 0.53422221 0.20470087]\n",
      " [0.62435566 0.7131494  0.53481011 0.43660754]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.28975634 0.0798017  0.30341555 0.14070806]\n",
      " [0.44462231 0.8620484  0.52434856 0.57728351]\n",
      " [0.72077306 0.97367916 0.88083695 0.84702662]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.2925874  0.12692232 0.20384942 0.27809537]\n",
      " [0.39000456 0.28899983 0.30389255 0.47141842]\n",
      " [0.62455858 0.63451744 0.36242692 0.67918202]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.21399541 0.19793206 0.31450287 0.33937997]\n",
      " [0.48368891 0.45379117 0.73873469 0.71451947]\n",
      " [0.72871828 0.69890801 0.8709126  0.99248842]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.27423137 0.16460859 0.18123081 0.2490339 ]\n",
      " [0.46005082 0.37525411 0.29136446 0.39136368]\n",
      " [0.64828412 0.63026731 0.6812499  0.72859324]\n",
      " [1.         1.         1.         1.        ]]\n",
      "[[0.24019448 0.08515065 0.39583496 0.37961732]\n",
      " [0.62198083 0.46780837 0.62050579 0.45444095]\n",
      " [0.73485323 0.85432019 0.79804219 0.57116376]\n",
      " [1.         1.         1.         1.        ]]\n",
      "Limits for the Monte Carlo,matrices as many as the clusters, columns as many as the variants, rows as many as the variants\n",
      "human\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.48731142, 0.15541343, 0.21045499, 0.52547256],\n",
       "        [0.61189057, 0.53225471, 0.67700458, 0.73227708],\n",
       "        [0.6257951 , 0.87510261, 0.85088915, 0.80047242],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.48565799, 0.29680276, 0.27258323, 0.28268924],\n",
       "        [0.50696586, 0.52507542, 0.34134759, 0.29573073],\n",
       "        [0.7206306 , 0.73991247, 0.62397651, 0.85580537],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.25487628, 0.11869668, 0.32808348, 0.3031173 ],\n",
       "        [0.37029746, 0.17765267, 0.6245509 , 0.46634874],\n",
       "        [0.73989799, 0.57847682, 0.98600851, 0.73141731],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.13444979, 0.22792548, 0.19680254, 0.16344107],\n",
       "        [0.14194892, 0.47078371, 0.5789359 , 0.24076149],\n",
       "        [0.53874555, 0.71500853, 0.8369092 , 0.44580457],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.28082645, 0.13596878, 0.2207573 , 0.13278658],\n",
       "        [0.57062278, 0.493332  , 0.5414516 , 0.64472042],\n",
       "        [0.72392588, 0.88080585, 0.64207028, 0.87907262],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.29309505, 0.18126581, 0.32174883, 0.08600264],\n",
       "        [0.34165651, 0.27176976, 0.39828276, 0.54270752],\n",
       "        [0.78042281, 0.68464435, 0.76801478, 0.97600349],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.38293667, 0.18877268, 0.40802505, 0.14932693],\n",
       "        [0.69265032, 0.39509444, 0.62565263, 0.17809463],\n",
       "        [0.7890225 , 0.59898308, 0.72097614, 0.62612416],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.13304072, 0.25990467, 0.28031793, 0.0466591 ],\n",
       "        [0.53441861, 0.48008419, 0.5250569 , 0.57623992],\n",
       "        [0.67102249, 0.79166169, 0.97677328, 0.63048195],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.32321559, 0.04577171, 0.32783652, 0.11384234],\n",
       "        [0.45301189, 0.29808569, 0.5578202 , 0.37220359],\n",
       "        [0.85910136, 0.78507272, 0.7834176 , 0.59766751],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.2543422 , 0.03363752, 0.13762468, 0.10791169],\n",
       "        [0.66623304, 0.37695723, 0.32519536, 0.4544042 ],\n",
       "        [0.8808355 , 0.56671094, 0.66819542, 0.80541342],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.2243446 , 0.1543584 , 0.12927406, 0.23469144],\n",
       "        [0.79327935, 0.36198331, 0.30064011, 0.36848379],\n",
       "        [0.97966506, 0.83822066, 0.70499824, 0.59149257],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.29658103, 0.01982171, 0.11192036, 0.08748839],\n",
       "        [0.68995327, 0.18150924, 0.30754384, 0.48171255],\n",
       "        [0.73546711, 0.63160952, 0.64919996, 0.92278772],\n",
       "        [1.        , 1.        , 1.        , 1.        ]])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.07596469, 0.13976462, 0.40151494, 0.40536303],\n",
       "        [0.2412112 , 0.33606007, 0.48144429, 0.43657786],\n",
       "        [0.78634637, 0.71374491, 0.60228467, 0.66641489],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.34199921, 0.43192543, 0.43918212, 0.15563738],\n",
       "        [0.65374494, 0.73713248, 0.72277922, 0.59781427],\n",
       "        [0.98933074, 0.91487176, 0.91907352, 0.6049072 ],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.04327732, 0.52364077, 0.01266824, 0.45529154],\n",
       "        [0.59535855, 0.53091516, 0.09366998, 0.65837482],\n",
       "        [0.61164403, 0.66257642, 0.4682903 , 0.79909541],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.09511649, 0.5019994 , 0.06149604, 0.18618819],\n",
       "        [0.3861344 , 0.58228108, 0.36578834, 0.3198758 ],\n",
       "        [0.63112959, 0.99863137, 0.74439389, 0.59033468],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.02989139, 0.58369466, 0.14812177, 0.04439152],\n",
       "        [0.45225362, 0.68981853, 0.53422221, 0.20470087],\n",
       "        [0.62435566, 0.7131494 , 0.53481011, 0.43660754],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.28975634, 0.0798017 , 0.30341555, 0.14070806],\n",
       "        [0.44462231, 0.8620484 , 0.52434856, 0.57728351],\n",
       "        [0.72077306, 0.97367916, 0.88083695, 0.84702662],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.2925874 , 0.12692232, 0.20384942, 0.27809537],\n",
       "        [0.39000456, 0.28899983, 0.30389255, 0.47141842],\n",
       "        [0.62455858, 0.63451744, 0.36242692, 0.67918202],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.21399541, 0.19793206, 0.31450287, 0.33937997],\n",
       "        [0.48368891, 0.45379117, 0.73873469, 0.71451947],\n",
       "        [0.72871828, 0.69890801, 0.8709126 , 0.99248842],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.27423137, 0.16460859, 0.18123081, 0.2490339 ],\n",
       "        [0.46005082, 0.37525411, 0.29136446, 0.39136368],\n",
       "        [0.64828412, 0.63026731, 0.6812499 , 0.72859324],\n",
       "        [1.        , 1.        , 1.        , 1.        ]]),\n",
       " array([[0.24019448, 0.08515065, 0.39583496, 0.37961732],\n",
       "        [0.62198083, 0.46780837, 0.62050579, 0.45444095],\n",
       "        [0.73485323, 0.85432019, 0.79804219, 0.57116376],\n",
       "        [1.        , 1.        , 1.        , 1.        ]])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Make a prob_distr for each correlation cluster, to choose the variants\n",
    "corr_distr_human=[]\n",
    "corr_distr_nean=[]\n",
    "for i in range(len(corrs_human)):\n",
    "    #print(np.random.rand(prob_xcorr.shape[0]).argsort())\n",
    "    prob_xcorr= np.random.random((variants,variants))\n",
    "    #np.random.shuffle(prob_xcorr, axis=1) #np.random.random(var+1)\n",
    "   \n",
    "    prob_xcorr=np.cumsum(prob_xcorr, axis=0)/np.sum(prob_xcorr,axis=0)\n",
    "    corr_distr_human.append(prob_xcorr)\n",
    "for i in range(len(corrs_neanderthal)):\n",
    "    prob_xcorr= np.random.random((variants,variants))\n",
    "    #print(prob_xcorr)\n",
    "    prob_xcorr=np.cumsum(prob_xcorr, axis=0)/np.sum(prob_xcorr, axis=0)\n",
    "    print(prob_xcorr)\n",
    "    corr_distr_nean.append(prob_xcorr)\n",
    "\n",
    "print(\"Limits for the Monte Carlo,matrices as many as the clusters, columns as many as the variants, rows as many as the variants\")    \n",
    "print(\"human\")\n",
    "display(corr_distr_human)\n",
    "print(\"nean\")\n",
    "display(corr_distr_nean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading :  3999 / 4000\n",
      "[2. 3. 1. 3. 0. 2. 1. 2. 0. 2. 3. 1. 0. 3. 1. 2. 3. 2. 2. 0. 3. 2. 2. 1.\n",
      " 0. 1. 1. 1. 3. 0. 3. 3. 1. 0. 0. 1. 1. 2. 0. 0. 2. 1. 3. 3. 0. 0. 2. 2.\n",
      " 2. 2. 3. 0. 3. 0. 0. 3. 2. 1. 2. 2. 1. 2. 0. 2. 2. 0. 3. 1. 3. 0. 2. 2.\n",
      " 0. 3. 3. 0. 3. 1. 3. 2. 0. 2. 2. 0. 3. 2. 3. 1. 1. 2. 0. 0. 2. 3. 3. 0.\n",
      " 0. 0. 3. 0.]\n",
      "[0. 1. 2. 0. 1. 3. 3. 2. 1. 0. 3. 3. 3. 2. 2. 3. 2. 1. 3. 2. 1. 2. 1. 0.\n",
      " 3. 1. 2. 2. 2. 1. 0. 0. 1. 1. 2. 2. 0. 3. 0. 2. 2. 0. 1. 0. 1. 3. 1. 3.\n",
      " 3. 2. 0. 0. 2. 2. 1. 1. 0. 1. 0. 0. 3. 2. 2. 3. 0. 2. 3. 2. 2. 1. 1. 3.\n",
      " 1. 0. 3. 1. 0. 3. 2. 2. 2. 1. 3. 2. 1. 2. 2. 1. 2. 1. 0. 0. 1. 3. 0. 0.\n",
      " 2. 2. 0. 1.]\n",
      "[0.0, 1.0, 2.0, 0.0, 1.0, 3.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 3.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0]\n",
      "[2, 1, 2, 0, 3, 3, 2, 1, 3, 1, 2]\n",
      "(4000, 3000)\n",
      "(4000, 3000)\n",
      "(600, 4000, 5)\n",
      "(600, 4000, 5)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import copy\n",
    "neanderthals=[]\n",
    "humans=[]\n",
    "\n",
    "genome_corr_h=[]\n",
    "genome_corr_n=[]\n",
    "\n",
    "for person in range(N_people):\n",
    "    _tmg=np.random.randint(variants)     #a variant random                  \n",
    "    clear_output(wait=\"True\")\n",
    "    print(\"Loading : \",person, \"/\", N_people )\n",
    "    #Build genome \n",
    "    human_genome_info=np.zeros(N_genes)       \n",
    "    \n",
    "    for i in range(len(corr_distr_human)):    #which cluster\n",
    "        for gene in corrs_human[i]:               #for every gene in the cluster\n",
    "            which_variants=0           \n",
    "            MC_2=np.random.random()\n",
    "            for lim in corr_distr_human[i][:,_tmg]:\n",
    "                if(MC_2<=lim):                          #use a monte carlo on markov to choose the variant\n",
    "                    human_genome_info[gene]=which_variants\n",
    "                    MC_2= 0\n",
    "                    _tmg=which_variants                 #jump to the other variant distr for the next it.\n",
    "                    break\n",
    "                else: which_variants+=1\n",
    "    _tmg=np.random.randint(variants)\n",
    "    print(human_genome_info)\n",
    "    genome_corr_h.append(copy.deepcopy(human_genome_info))  #now i have the genome, i copy that.\n",
    "    nean_genome_info=np.zeros(N_genes)\n",
    "    for i in range(len(corr_distr_nean)):                   #same for neanderthal\n",
    "        for gene in corrs_neanderthal[i]:\n",
    "            which_variants=0           \n",
    "            MC_2=np.random.random()\n",
    "            for lim in corr_distr_nean[i][:,_tmg]:\n",
    "                if(MC_2<=lim): \n",
    "                    nean_genome_info[gene]=which_variants\n",
    "                    MC_2= 0\n",
    "                    _tmg=which_variants\n",
    "                    break\n",
    "                else: which_variants+=1\n",
    "    \n",
    "    print(nean_genome_info)\n",
    "    print(list(nean_genome_info))\n",
    "    \n",
    "    genome_corr_n.append(copy.deepcopy(nean_genome_info))\n",
    "\n",
    "    #Build genes:\n",
    "\n",
    "    human_genome=[]\n",
    "    nean_genome=[]\n",
    "\n",
    "    for i in range(len(human_genome_info)):\n",
    "    \n",
    "        human_genome.append(genes[i][int(human_genome_info[i])]) #put the complete gene in an array .\n",
    "    for i in range(len(nean_genome_info)):                       #as decided with the monte carlo.\n",
    "        nean_genome.append(genes[i][int(nean_genome_info[i])])\n",
    "    human_genome_info=[]\n",
    "    nean_genome_info=[]\n",
    "\n",
    "    #build intragenic\n",
    "    human_intra=[]                                                #build intragenic\n",
    "    nean_intra=[]\n",
    "    for i in range(len(intragenic_char_humans)):                  \n",
    "        human_intra.append(np.random.randint(4,size=int(intragenic_char_humans[i])))\n",
    "\n",
    "    for i in range(len(intragenic_char_neanderthal)):\n",
    "        nean_intra.append(np.random.randint(4,size=int(intragenic_char_humans[i])))\n",
    "\n",
    "    #build genome\n",
    "\n",
    "    human_DNA= list(human_intra[0])\n",
    "    nean_DNA= list(nean_intra[0])\n",
    "    print(human_DNA)\n",
    "    for i in range(0,N_genes):\n",
    "        for nuc in human_genome[i]:\n",
    "            human_DNA.append(nuc)\n",
    "        for nuc in human_intra[i+1]:\n",
    "            human_DNA.append(nuc)\n",
    "        for nuc in nean_genome[i]:\n",
    "            nean_DNA.append(nuc)\n",
    "        for nuc in nean_intra[i+1]:\n",
    "            nean_DNA.append(nuc)\n",
    "    #to letters\n",
    "\n",
    "    human_genome=[]\n",
    "    nean_genome=[]\n",
    "    nean_intra=[]\n",
    "    humna_intra=[]\n",
    "\n",
    "    my_d={0:'A',1:'C',2:'G',3:'T'}\n",
    "    for i in range(len(human_DNA)):\n",
    "        human_DNA[i]=my_d[human_DNA[i]]\n",
    "    for i in range(len(nean_DNA)):\n",
    "        nean_DNA[i]=my_d[nean_DNA[i]]\n",
    "    \n",
    "    humans.append(human_DNA)\n",
    "    neanderthals.append(nean_DNA)\n",
    "humans=np.array(humans)\n",
    "neanderthals=np.array(neanderthals)\n",
    "\n",
    "print(humans.shape)\n",
    "print(neanderthals.shape)\n",
    "\n",
    "#divide in words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h_DNA= np.array(np.split(humans, sentence_length//word_length, axis=1  ))\n",
    "n_DNA= np.array(np.split(neanderthals, sentence_length//word_length , axis=1 ))\n",
    "\n",
    "print(h_DNA.shape)\n",
    "print(n_DNA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the words frequency for DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e86cc3757dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#make words strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m h_DNA = np.array([[''.join(h_DNA[i,j,:]) for i in range(h_DNA.shape[0]) ]for \n\u001b[0;32m----> 4\u001b[0;31m                   j in range(h_DNA.shape[1])])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#make words strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m n_DNA = np.array([[''.join(n_DNA[i,j,:]) for i in range(n_DNA.shape[0]) ]for \n",
      "\u001b[0;32m<ipython-input-14-e86cc3757dc5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#make words strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m h_DNA = np.array([[''.join(h_DNA[i,j,:]) for i in range(h_DNA.shape[0]) ]for \n\u001b[0;32m----> 4\u001b[0;31m                   j in range(h_DNA.shape[1])])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#make words strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m n_DNA = np.array([[''.join(n_DNA[i,j,:]) for i in range(n_DNA.shape[0]) ]for \n",
      "\u001b[0;32m<ipython-input-14-e86cc3757dc5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDNA_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msentence_length\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN_people\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#make words strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m h_DNA = np.array([[''.join(h_DNA[i,j,:]) for i in range(h_DNA.shape[0]) ]for \n\u001b[0m\u001b[1;32m      4\u001b[0m                   j in range(h_DNA.shape[1])])\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#make words strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "DNA_length= sentence_length*N_people\n",
    "#make words strings.\n",
    "h_DNA = np.array([[''.join(h_DNA[i,j,:]) for i in range(h_DNA.shape[0]) ]for \n",
    "                  j in range(h_DNA.shape[1])])\n",
    "#make words strings.\n",
    "n_DNA = np.array([[''.join(n_DNA[i,j,:]) for i in range(n_DNA.shape[0]) ]for \n",
    "                  j in range(n_DNA.shape[1])])\n",
    "\n",
    "print(h_DNA.shape)\n",
    "\n",
    "h_DNA_check= h_DNA.reshape(DNA_length//word_length)\n",
    "n_DNA_check= n_DNA.reshape(DNA_length//word_length)\n",
    "display(h_DNA_check)\n",
    "h_DNA_check1=[]\n",
    "n_DNA_check1=[]\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as  plt\n",
    "\n",
    "\n",
    "##HUMAN\n",
    "print(\"here\")\n",
    "counts_h=dict(Counter(h_DNA_check).most_common(50))\n",
    "print(\"there\")\n",
    "labels_h, values_h = zip(*counts_h.items())\n",
    "\n",
    "#sort\n",
    "indsort_h = np.argsort(values_h)[::-1]\n",
    "\n",
    "#re_arrange\n",
    "labels_h= np.array(labels_h)[indsort_h]\n",
    "values_h= np.array(values_h)[indsort_h]\n",
    "indexes_h = np.arange(len(values_h))\n",
    "bar_width=0.2\n",
    "plt.bar(indexes_h, values_h)\n",
    "plt.xticks(indexes_h+bar_width,labels_h, rotation= 90)\n",
    "print(len(counts_h))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "##NEANDERTHAL\n",
    "print(\"here\")\n",
    "counts_n=dict(Counter(n_DNA_check).most_common(50))\n",
    "print(\"there\")\n",
    "labels_n, values_n = zip(*counts_n.items())\n",
    "\n",
    "#sort\n",
    "indsort_n = np.argsort(values_n)[::-1]\n",
    "\n",
    "#re_arrange\n",
    "labels_n= np.array(labels_n)[indsort_n]\n",
    "values_n= np.array(values_n)[indsort_n]\n",
    "indexes_n = np.arange(len(values_n))\n",
    "bar_width=0.2\n",
    "plt.bar(indexes_n, values_n)\n",
    "plt.xticks(indexes_n+bar_width,labels_n, rotation= 90)\n",
    "print(len(counts_n))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 600)\n",
      "6400\n",
      "1025\n"
     ]
    }
   ],
   "source": [
    "h_DNA_NN=[' '.join(h_DNA[i,:]) for i in range(h_DNA.shape[0])]\n",
    "n_DNA_NN=[' '.join(n_DNA[i,:]) for i in range(n_DNA.shape[0])]\n",
    "\n",
    "DNA_NN = h_DNA_NN+n_DNA_NN\n",
    "Y = [1]*len(h_DNA_NN)+[0]*len(n_DNA_NN)\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(DNA_NN)\n",
    "\n",
    "encoded_docs = tokenizer.texts_to_sequences(DNA_NN)\n",
    "max_length = max([len(s.split()) for s in DNA_NN])\n",
    "X = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42, shuffle = True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(len(Y_train))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build an LSTM NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edoardospadetto/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 32)           32800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                1720      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 34,581\n",
      "Trainable params: 34,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam, Adadelta, RMSprop\n",
    "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten, Dropout\n",
    "from keras.layers import Embedding, GlobalAveragePooling1D, LSTM, SimpleRNN, GRU\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32, input_length = max_length, dropout = 0.2))\n",
    "#model.add(SimpleRNN(10, dropout = 0.2, recurrent_dropout = 0.2))  #this sucks\n",
    "model.add(LSTM(10, dropout = 0.2, recurrent_dropout = 0.2))  #totally killing it\n",
    "#model.add(Conv1D(10, dropout = 0.2, recurrent_dropout = 0.2)) \n",
    "\n",
    "model.add(Dense(5,\n",
    "                kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "checkpoint = ModelCheckpoint(\"weights.best.hdf5\", monitor = 'val_acc', verbose = 1, \n",
    "                             save_best_only = True, mode = 'max')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edoardospadetto/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/7\n",
      "5120/5120 [==============================] - 68s 13ms/step - loss: 0.7513 - accuracy: 0.4977 - val_loss: 0.7317 - val_accuracy: 0.5008\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edoardospadetto/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120/5120 [==============================] - 69s 13ms/step - loss: 0.7227 - accuracy: 0.5047 - val_loss: 0.7127 - val_accuracy: 0.4914\n",
      "Epoch 3/7\n",
      " 950/5120 [====>.........................] - ETA: 55s - loss: 0.7124 - accuracy: 0.5168"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dc2ba8506edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(X_train, Y_train, \n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     callbacks = [checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs = epochs, verbose = 1, validation_split = 0.2, batch_size = 50, shuffle = True, \n",
    "                    callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "predicted_labels = model.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, [np.round(i[0]) for i in predicted_labels])\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(cm, cmap = plt.cm.Blues)\n",
    "plt.title('Normalized confusion matrix', fontsize = 15)\n",
    "plt.colorbar()\n",
    "plt.xlabel('True label', fontsize = 15)\n",
    "plt.ylabel('Predicted label', fontsize = 15)\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "             horizontalalignment = 'center', verticalalignment = 'center', fontsize = 20,\n",
    "             color='white' if cm[i, j] > 0.5 else 'black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
